import sys, os, math, tempfile, joblib, numpy as np, librosa
from pathlib import Path
from fastapi import FastAPI, File, UploadFile, Header, Depends, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from dotenv import load_dotenv

# Firebase + Supabase
import firebase_admin
from firebase_admin import credentials, auth as firebase_auth
from supabase import create_client

# Gemini AI
import google.generativeai as genai

# Local import
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from ml_training.train_audio_features import extract_features


# ============================================================
# âš™ï¸ ENVIRONMENT + MODEL SETUP
# ============================================================
load_dotenv()
BASE_DIR = Path(__file__).resolve().parents[1]
MODEL_DIR = BASE_DIR / "ml_training" / "models"

# Load Models
audio_bundle = joblib.load(MODEL_DIR / "audio_parkinson_model_calibrated.pkl")
audio_model, audio_scaler = audio_bundle["model"], audio_bundle.get("scaler", None)

pca_bridge = joblib.load(MODEL_DIR / "audio_pca22_bridge.pkl")["pipeline"]
fusion_bundle = joblib.load(MODEL_DIR / "fusion_meta_model_pca22.pkl")
fusion_model = fusion_bundle["meta_model"]

print("âœ… All models loaded successfully (Audio + PCA Bridge + Fusion)")

# ============================================================
# ðŸŒ FASTAPI CONFIG
# ============================================================
app = FastAPI(title="Parkinson Detection Backend")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # or restrict to frontend URLs
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ============================================================
# ðŸ” FIREBASE
# ============================================================
FIREBASE_PRIVATE_KEY = os.getenv("FIREBASE_PRIVATE_KEY")
FIREBASE_CLIENT_EMAIL = os.getenv("FIREBASE_CLIENT_EMAIL")
FIREBASE_PROJECT_ID = os.getenv("FIREBASE_PROJECT_ID")

if FIREBASE_PRIVATE_KEY and FIREBASE_CLIENT_EMAIL and FIREBASE_PROJECT_ID:
    cred_dict = {
        "type": "service_account",
        "project_id": FIREBASE_PROJECT_ID,
        "private_key_id": "dummy_key_id",
        "private_key": FIREBASE_PRIVATE_KEY.replace("\\n", "\n"),
        "client_email": FIREBASE_CLIENT_EMAIL,
        "client_id": "dummy_client_id",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
        "client_x509_cert_url": f"https://www.googleapis.com/robot/v1/metadata/x509/{FIREBASE_CLIENT_EMAIL}",
    }
    try:
        cred = credentials.Certificate(cred_dict)
        firebase_admin.initialize_app(cred)
        print("âœ… Firebase initialized")
    except Exception as e:
        print("âš ï¸ Firebase already initialized or error:", e)
else:
    print("âš ï¸ Firebase credentials missing")

# ============================================================
# ðŸ—ƒï¸ SUPABASE
# ============================================================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
SUPABASE_BUCKET = os.getenv("SUPABASE_BUCKET", "audio-uploads")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY) if SUPABASE_URL and SUPABASE_KEY else None

# ============================================================
# ðŸ¤– GEMINI AI
# ============================================================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    print("âœ… Gemini AI configured")
else:
    print("âš ï¸ Gemini API key missing")

# ============================================================
# ðŸ§  VERIFY TOKEN
# ============================================================
def verify_token(authorization: str = Header(None)):
    if not authorization:
        raise HTTPException(status_code=401, detail="Missing authorization header")
    token = authorization.split(" ", 1)[1] if authorization.lower().startswith("bearer ") else authorization
    try:
        return firebase_auth.verify_id_token(token)
    except Exception as e:
        raise HTTPException(status_code=401, detail=f"Invalid token: {e}")

# ============================================================
# ðŸŽµ Predict from File (Audio + PCA Bridge + Features)
# ============================================================
def predict_from_file(file_path: str):
    feats = extract_features(file_path)
    feats = np.nan_to_num(feats).reshape(1, -1)

    # ðŸŽ§ Audio (Full)
    x_audio = audio_scaler.transform(feats) if audio_scaler else feats
    p_audio = float(audio_model.predict_proba(x_audio)[0, 1])

    # ðŸ§© PCA Bridge (22D)
    pca_step = pca_bridge.named_steps.get("pca", None)
    X_pca = pca_step.transform(feats) if pca_step else np.zeros((1, 22))
    p_pca22 = float(pca_bridge.predict_proba(feats)[0, 1])

    # ðŸ§  Fusion
    f_input = np.array([[p_pca22, p_audio]])
    p_fusion = float(fusion_model.predict_proba(f_input)[0, 1])

    label = "Parkinson" if p_fusion >= 0.5 else "Healthy"

    # âœ¨ AI Summary (optional)
    if p_fusion < 0.4:
        ai_summary = "Your voice appears stable and healthy with strong acoustic consistency."
    elif p_fusion < 0.65:
        ai_summary = "Some mild irregularities detected in voice features â€” consider regular monitoring."
    else:
        ai_summary = "AI detected significant voice variations possibly linked to Parkinsonâ€™s symptoms."

    return label, p_audio, p_pca22, p_fusion, X_pca.tolist()[0], ai_summary



# ============================================================
# ðŸ§¹ JSON CLEANER
# ============================================================
def clean_json(obj):
    if isinstance(obj, np.ndarray):
        return [clean_json(x) for x in obj.tolist()]
    if isinstance(obj, (list, tuple)):
        return [clean_json(x) for x in obj]
    if isinstance(obj, dict):
        return {k: clean_json(v) for k, v in obj.items()}
    if isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return 0.0
        return float(obj)
    return obj
# ============================================================
# ðŸ“¤ Upload Endpoint (Audio + PCA Fusion)
# ============================================================
@app.post("/upload")
async def upload(file: UploadFile = File(...), user: dict = Depends(verify_token)):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.write(await file.read())
    tmp.flush()
    tmp.close()

    label, p_audio, p_pca22, p_fusion, pca_features, ai_summary = predict_from_file(tmp.name)

    data = {
        "user_id": user["uid"],
        "audio_full_proba": p_audio,
        "pca22_proba": p_pca22,
        "fusion_proba": p_fusion,
        "final_label": label,
        "ai_summary": ai_summary,
        "pca_features": pca_features,
    }

    return JSONResponse(data)

# ============================================================
# ðŸ“Š USER RESULTS
# ============================================================
@app.get("/user/results")
def get_user_results(user: dict = Depends(verify_token)):
    if not supabase:
        return {"results": []}
    uid = user["uid"]
    res = supabase.table("results").select("*").eq("user_id", uid).order("created_at", desc=True).execute()
    return {"results": res.data}

# ============================================================
# ðŸ¤– GEMINI CHATBOT
# ============================================================
@app.post("/chatbot")
async def chatbot(request: Request):
    try:
        data = await request.json()
        message = data.get("message", "").strip()
        if not message:
            return {"reply": "Please type a question."}

        print(f"ðŸ’¬ Gemini Request: {message}")
        model = genai.GenerativeModel("gemini-2.0-flash")
        prompt = (
            "You are a friendly AI assistant inside a Parkinsonâ€™s voice health dashboard. "
            "Explain voice analysis metrics (like jitter, shimmer, HNR, MFCCs, and health score) simply and clearly. "
            "Keep answers concise (2â€“4 sentences) and supportive. "
            "For casual questions, reply kindly like a human friend. "
            f"User asked: '{message}'"
        )

        response = model.generate_content(prompt)
        reply_text = response.text.strip() if response and response.text else "I'm here to help you understand your voice results!"
        print(f"âœ… Gemini Reply: {reply_text}")
        return {"reply": reply_text}

    except Exception as e:
        import traceback
        traceback.print_exc()
        print("âŒ Gemini Chatbot Error:", e)
        return {"reply": "Sorry, I couldnâ€™t connect to the AI assistant."}

# ============================================================
# ðŸ  ROOT
# ============================================================
@app.get("/")
def root():
    return {"message": "âœ… Parkinson Detection Backend with PCA(22) + Fusion + Gemini AI running successfully"}
